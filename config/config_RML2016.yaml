# data parameters
dataset_path: ../amc_dataset/RML2016/RML2016.10a_dict.pkl
save_path: checkpoint/paper/size_2016/vit
epoch: 150

# supervised learning parameters
model_name: robustcnn
batch_size: 128

# training parameters
cuda: True
gpu_ids: [0]  # set the GPU ids to use, e.g. [0] or [1, 2]
lr: 0.1
lr_gamma: 0.8
print_iter: 400

# test parameters
test_dataset_path: ../amc_dataset/RML2016/RML2016.10a_dict.pkl
load_test_path: checkpoint/paper/size_2016/vit
show_conf_matrix: False

# AMC RML2016.10A dataset configuration
total_class: ['AM-SSB', 'CPFSK', 'QPSK', 'GFSK', 'PAM4', 'QAM16', 'WBFM', '8PSK', 'QAM64', 'AM-DSB', 'BPSK']
train_class_indice: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
test_class_indice: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]

# few-shot learning parameters
fs_model: vit # robustcnn, rewis, vit, lstm, daelstm
num_support: 15 # 15
num_query: 10  # 10

##### Size test parameters
### train
snr_range: [-10, 18]
train_sample_size: 128
test_sample_size: [128] #[16, 32, 64, 128]
save_folder_name: -10to18
train_proportion: 0.8
data_divide: True  # divide train, test dataset

### test
test_snr_range: [-20,20]
load_model_name: 99.tar

# transformer parameters
extension: False # if True, set patch_size[0] & in_size[0] -> 4
trans_lr: 0.001

test_snr_range: [-20,18]

in_channels: 1
patch_size: [2, 16] #12
embed_dim: 108
num_layers: 8
num_heads: 9
mlp_dim: 16
in_size: [2,128]
num_classes: 11


# # best setting
# in_channels: 1
# patch_size: [2, 16] #12
# embed_dim: 108
# num_layers: 8
# num_heads: 9
# mlp_dim: 8
# in_size: [2,128]
# num_classes: 11