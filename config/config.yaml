# data parameters
dataset_path: ./amc_dataset/RML2018
snr_range: [-10, 20]
save_path: ./checkpoint/unseen/vit/testB
epoch: 50

# supervised learning parameters
model_name: robustcnn
batch_size: 128 #resnet:1024 / robustcnn: 128

# training parameters
cuda: True
gpu_ids: [0]  # set the GPU ids to use, e.g. [0] or [1, 2]
train_proportion: 0.8
lr: 0.01 #  resnet: 0.001 / robustcnn: 0.01
print_iter: 400

# test parameters
test_dataset_path: ./amc_dataset/RML2018
load_test_path: ./checkpoint/unseen/vit/testB/49.tar

# AMC dataset configuration
# total class indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,22, 23]
# easy class indices: [0, 1, 3, 4, 5, 12, 18, 20, 21, 22, 23]
# difficult class indices: [2, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 19]
total_class: ['OOK', '4ASK', '8ASK', 'BPSK', 'QPSK', '8PSK', '16PSK', '32PSK', '16APSK', '32APSK', '64APSK', '128APSK', '16QAM', '32QAM', '64QAM', '128QAM', '256QAM', 'AM-SSB-WC', 'AM-SSB-SC', 'AM-DSB-WC', 'AM-DSB-SC', 'FM', 'GMSK', 'OQPSK']
train_class_indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,22, 23]
test_class_indices: [0, 7, 10, 11, 22]

# few-shot learning parameters
fs_model: vit # robustcnn, protonet, vit
num_support: 5
num_query: 10

# transformer parameters
trans_lr: 0.001

in_channels: 1
patch_size: [2, 16]
embed_dim: 36
num_layers: 8
num_heads: 9
mlp_dim: 32
in_size: [2,1024]
num_classes: 24
