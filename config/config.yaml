# ### Models ###
# vit_main: proposed Meta-Transformer(default)
# vit_sub: proposed Meta-Transformer (sub frame length)
# daelstm-meta: LSTM based AMC model(Meta-Learning)
# daelstm-super: Supervised Learning version
# protonet: Meta-Learning example
# resnet: resnet based AMC model
# robustcnn: CNN based model which is using 4 x 1024 frame size(reverse and concatenate)
model: vit_main

# train parameters
dataset_path: ./amc_dataset/RML2018
save_path: ./checkpoint/paper/learning

cuda: True
gpu_ids: [0]  # set the GPU ids to use, e.g. [0] or [1, 2]
print_iter: 400 # print training info

snr_range: [-10, 20]
train_proportion: 0.8

# test parameters
test_dataset_path: ./amc_dataset/RML2018
load_test_path: ./checkpoint/paper/learning
load_model_name: 0.tar
show_conf_matrix: False
show_result: True
save_result: True
test_snr_range: [-20,20]

# AMC dataset configuration
# total class indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,22, 23]
# easy class indices: [0, 1, 3, 4, 5, 12, 18, 20, 21, 22, 23]
# difficult class indices: [2, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 19]
total_class: ['OOK', '4ASK', '8ASK', 'BPSK', 'QPSK', '8PSK', '16PSK', '32PSK', '16APSK', '32APSK', '64APSK', '128APSK', '16QAM', '32QAM', '64QAM', '128QAM', '256QAM', 'AM-SSB-WC', 'AM-SSB-SC', 'AM-DSB-WC', 'AM-DSB-SC', 'FM', 'GMSK', 'OQPSK']
train_class_indices: [1, 3, 5, 7, 9, 10, 11, 14, 17, 19, 21, 22] # 12
test_class_indices: [0, 2, 4, 6, 12] # 5

# few-shot learning parameters
num_support: 5
num_query: 10

##### frame length variation eval parameters
train_sample_len: 1024
test_sample_len: [1024] # [64, 128, 256, 512, 1024]

# input frame padding [self_duplicate(default), zero]
padding: 'self_duplicate'

