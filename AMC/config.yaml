# data parameters
dataset_path: /home/inclab2/Gitrepo/meta-transformer-amc/amc_dataset/RML2018
dataset_path_2016: /home/inclab2/Gitrepo/meta-transformer-amc/amc_dataset/RML2016/RML2016.10a_dict.pkl
save_path: checkpoint/paper/size_2016/vit
epoch: 50

# supervised learning parameters
model_name: robustcnn
batch_size: 128

# training parameters
cuda: True
gpu_ids: [0]  # set the GPU ids to use, e.g. [0] or [1, 2]
lr: 0.01
lr_gamma: 0.8
print_iter: 400

# test parameters
test_dataset_path: /home/inclab2/Gitrepo/meta-transformer-amc/amc_dataset/RML2018
test_dataset_path_2016: /home/inclab2/Gitrepo/meta-transformer-amc/amc_dataset/RML2016/RML2016.10a_dict.pkl
load_test_path: checkpoint/paper/size_2016/vit
show_conf_matrix: False

# AMC dataset configuration
total_class: ['OOK', '4ASK', '8ASK', 'BPSK', 'QPSK', '8PSK', '16PSK', '32PSK', '16APSK', '32APSK', '64APSK', '128APSK', '16QAM', '32QAM', '64QAM', '128QAM', '256QAM', 'AM-SSB-WC', 'AM-SSB-SC', 'AM-DSB-WC', 'AM-DSB-SC', 'FM', 'GMSK', 'OQPSK']
train_class_indice: [0, 1, 3, 4, 5, 12, 18, 20, 21, 22, 23, 2, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 19] # [0, 1, 3, 4, 5, 12, 13, 14, 2, 6, 7, 8] # [0, 1, 3, 4, 5, 12, 18, 20, 21, 22, 23]
test_class_indice: [0, 1, 3, 4, 5, 12, 18, 20, 21, 22, 23, 2, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 19] # [18, 20, 21, 22, 23, 9, 10, 11,15, 16, 17, 19] #[2, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 19]

# AMC RML2016.10A dataset configuration
total_class16: ['AM-SSB', 'CPFSK', 'QPSK', 'GFSK', 'PAM4', 'QAM16', 'WBFM', '8PSK', 'QAM64', 'AM-DSB', 'BPSK']
train_class_indices16: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
test_class_indices16: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]

# few-shot learning parameters
fs_model: vit # robustcnn, rewis, vit, lstm, daelstm
num_support: 5
num_query: 10

##### Size test parameters
### train
snr_range: [-10, 20]
train_sample_size: 1024
train_sample_size_2016: 128
test_sample_size: [1024] #[16, 32, 64, 128, 256, 512, 1024]
save_folder_name: -10to20
train_proportion: 0.8
data_divide: True  # divide train, test dataset

### test
test_snr_range: [-20,20]
load_model_name: 49.tar

# transformer parameters
extension: False # if True, set patch_size[0] & in_size[0] -> 4
trans_lr: 0.001

# RML 2018
# in_channels: 1
# patch_size: [2, 16] #12
# embed_dim: 36
# num_layers: 8
# num_heads: 9
# mlp_dim: 32
# in_size: [2,1024]
# num_classes: 24

# RML 2016
in_channels: 1
patch_size: [2, 16] #12
embed_dim: 36
num_layers: 8
num_heads: 9
mlp_dim: 32
in_size: [2,128]
num_classes: 11
