# data parameters
dataset_path: ./amc_dataset/RML2018
save_path: ./checkpoint/learning/vit/test
epoch: 50 # daelstm:150

# supervised learning parameters
model_name: robustcnn # daelstm, resnet, robustcnn
batch_size: 128 # daelstm: 128, resnet:1024 / robustcnn: 128

# training parameters
cuda: True
gpu_ids: [0]  # set the GPU ids to use, e.g. [0] or [1, 2]

train_proportion: 0.8
lr: 0.01 #  resnet: 0.001 / robustcnn: 0.01
lr_gamma: 0.8
print_iter: 400

# test parameters
test_dataset_path: ./amc_dataset/RML2018
load_test_path: ./checkpoint/learning/vit/-10to20
show_conf_matrix: False

# AMC dataset configuration
# total class indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,22, 23]
# easy class indices: [0, 1, 3, 4, 5, 12, 18, 20, 21, 22, 23]
# difficult class indices: [2, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 19]
total_class: ['OOK', '4ASK', '8ASK', 'BPSK', 'QPSK', '8PSK', '16PSK', '32PSK', '16APSK', '32APSK', '64APSK', '128APSK', '16QAM', '32QAM', '64QAM', '128QAM', '256QAM', 'AM-SSB-WC', 'AM-SSB-SC', 'AM-DSB-WC', 'AM-DSB-SC', 'FM', 'GMSK', 'OQPSK']
train_class_indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,22, 23]
test_class_indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,22, 23]

# few-shot learning parameters
fs_model: vit # robustcnn, protonet, vit
num_support: 5
num_query: 10


##### Size test parameters
### train
snr_range: [-10, 20]
train_sample_size: 1024
test_sample_size: [1024] # [64, 128, 256, 512, 1024]
train_proportion: 0.75
data_divide: True  # divide train, test dataset

### test
test_snr_range: [-20,20]
load_model_name: 49.tar

# transformer parameters
trans_lr: 0.001

# main encoder
in_channels: 1
patch_size: [2, 16]
embed_dim: 36
num_layers: 8
num_heads: 9
mlp_dim: 32
in_size: [2,1024]
num_classes: 24

# # sub encoder
# in_channels: 1
# patch_size: [2, 16] #12
# embed_dim: 108
# num_layers: 8
# num_heads: 9
# mlp_dim: 16
# in_size: [2,128]
# num_classes: 24